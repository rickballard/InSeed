# The Steward’s Handbook (v2.0 — Full Edition)

> **Audience:** Humans who choose to stand between AI systems and the communities, organizations, or institutions those systems affect.  
> **Mission:** Provide practical guidance, ethics, and tools so Stewards can protect dignity, agency, and truth in an AI-saturated civilization.

---

## 0. How to Use This Handbook

- This is a **living manual**, not a sacred text.  
- Fork it, annotate it, localize it, argue with it.  
- Use it to:
  - Train new Stewards
  - Structure Steward Circles
  - Design governance in organizations and communities
  - Inform policy and advocacy

---

## 1. What Is a Steward?

A **Steward** is a role in hybrid human–AI society:

- Guardian of **local agency** against the drift toward automated centralization.
- Translator between:
  - Technical systems (models, data, infrastructure)
  - Institutional systems (laws, policies, budgets)
  - Human realities (culture, trauma, history, aspirations)
- Designer and protector of **guardrails, receipts, and reversible moves**.

Stewards do not work alone. They operate in **Steward Circles**: small, diverse groups with a clear mandate to oversee AI use in a particular context (a city, hospital, school board, company, or online community).

---

## 2. The Steward’s Mandate

Every Steward Circle should have an explicit mandate, such as:

1. **Oversight of AI Use**
   - Identify where AI is used in the system.
   - Track purpose, scope, and risk level of each deployment.
   - Ensure each critical AI has:
     - An owner
     - A clear purpose statement
     - A documented risk assessment

2. **Guardrails and Governance**
   - Co-design policies for:
     - Data use and protection
     - Model selection and monitoring
     - Human-in-the-loop and human-on-the-loop requirements
   - Ensure policies are enforceable and understandable.

3. **Transparency, Receipts, and Explanation**
   - Insist on **receipts-by-default**:
     - Logs of high-stakes decisions
     - Rationale or criteria where possible
     - Appeals and redress mechanisms
   - Ensure explanations are **comprehensible** to affected people.

4. **Community Liaison and Deliberation**
   - Bring community stories, concerns, and values into technical and strategic discussions.
   - Facilitate deliberative spaces where people can question AI use and propose alternatives.

5. **Ethical Escalation**
   - When something feels wrong:
     - Document it.
     - Convene the circle.
     - Escalate to leadership, regulators, or the public if necessary.

---

## 3. Steward Competency Model

### 3.1 Mindset

Stewards need:

- **Curiosity** – willingness to ask “How does this actually work?” instead of treating AI as magic.
- **Humility** – awareness of limits; desire to invite critique and share responsibility.
- **Moral Courage** – capacity to say “no” or “wait” when systems are unsafe, even under pressure.
- **Solidarity** – orientation toward collective well-being, not just organizational success.

### 3.2 Skills

1. **Systems Thinking**
   - See how technical systems, incentives, policies, and human behavior interact.
   - Draw causal diagrams and feedback loops for key contexts (e.g., welfare, policing, credit).

2. **AI Literacy**
   - Understand basic concepts:
     - Data → training → inference
     - Bias, drift, robustness
     - Limits of explainability
   - Recognize when to call in deeper technical expertise.

3. **Governance & Policy Literacy**
   - Know how decisions are made in your organization or community:
     - Formal processes
     - Informal power structures
   - Understand key legal frameworks (privacy, discrimination, safety, due process).

4. **Facilitation & Conflict Handling**
   - Run meetings where:
     - Non-technical voices are heard.
     - Disagreements are surfaced and worked through.
   - Handle tension between speed and safety.

5. **Documentation & Receipts**
   - Maintain clear records:
     - What was decided
     - Why and by whom
     - What safeguards were put in place
   - Enable future audits and learning.

---

## 4. Steward Circles: Structure and Rituals

### 4.1 Circle Composition

Aim for diversity across:

- Roles (technical, legal, frontline, leadership, community)
- Demographics (age, gender, background)
- Perspectives (optimists, skeptics, critics)

### 4.2 Example Mandate Statement

> The Steward Circle for [Org/City] is charged with ensuring that AI systems deployed in our context are aligned with our values, laws, and community needs; that they are transparent and contestable; and that harms and risks are proactively identified and addressed.

### 4.3 Monthly Steward Circle Ritual (Template)

1. **Opening Check-In (10–15 minutes)**
   - “What have you seen this month that worries or encourages you about AI use here?”

2. **New AI Initiatives (20–30 minutes)**
   - Review any proposed or newly deployed AI systems.
   - For each:
     - What is the purpose?
     - Who is affected?
     - What data is used?
     - What are the potential harms?

3. **Incident & Harm Review (20–30 minutes)**
   - Go through:
     - Complaints
     - Near misses
     - Observed anomalies
   - Ask:
     - Was there a receipt?
     - Was there an appeals path?
     - What should change?

4. **Policy / Protocol Updates (20 minutes)**
   - Do any policies need clarification or revision?
   - Are there new guidelines we should draft?

5. **Care & Rotation (10 minutes)**
   - Does anyone feel overwhelmed?
   - Are any roles due for rotation?
   - Do we need more training or external help?

---

## 5. Core Steward Tools and Patterns

### 5.1 Receipts-by-Default

For each high-stakes AI system, Stewards should push for:

- **Decision Logs**
  - Time, context, model version.
  - Input type and key output.
  - Human approver, if any.

- **Model Cards / System Profiles**
  - Purpose, training data sources, known limits.
  - Risk classification (low, medium, high).

- **Appeals & Redress**
  - A documented process for:
    - Challenging outcomes.
    - Requesting human review.
    - Correcting errors.

### 5.2 Truth Mesh Practice

Instead of a single, “official” view:

- Collect inputs from:
  - Internal data and analytics.
  - External journalism and reports.
  - Community testimony.
  - Scientific and academic sources.

Ask AI systems to:

- Surface **multiple** plausible interpretations.
- Highlight disagreements and uncertainty.
- Provide references and source pathways.

Stewards then:

- Facilitate discussions around these meshes.
- Document how final decisions were made.

### 5.3 Reversible Moves

Before any major AI deployment:

- Define clear **pilot boundaries**:
  - Where and for whom?
  - How long?

- Define **metrics & harm indicators**:
  - What would success look like?
  - What harms are intolerable?

- Pre-commit to **rollback conditions**:
  - “If X happens, we pause or revert.”

---

## 6. Working with Leadership

### 6.1 Speaking Leadership’s Language

Leaders worry about:

- Legal risk
- Reputational risk
- Operational continuity
- Political fallout
- Financial performance

Stewards should translate ethical concerns into:

- “This exposes us to regulators.”
- “This will create future headlines we cannot control.”
- “This undermines trust with staff and communities.”
- “This creates lock-in that reduces strategic flexibility.”

### 6.2 Offering Alternatives

When saying “no” or “not yet,” Stewards should also offer:

- Safer pilot designs.
- Narrower use-cases.
- Additional guardrails.
- Phased approaches (test → evaluate → expand).

---

## 7. Working with Communities

### 7.1 Building Trust

Stewards need to be:

- Visible: known and reachable.
- Honest: acknowledging trade-offs and uncertainty.
- Humble: willing to admit errors, change course, and apologize.

### 7.2 Listening Structures

Create recurring spaces where community members can:

- Ask questions about AI use.
- Raise concerns and share stories.
- Propose changes or alternatives.

Capture what is heard and feed it back into:

- Policy updates.
- System design.
- Leadership briefings.

---

## 8. Steward Self-Care and Rotation

Stewardship can be heavy:

- Exposure to harms and injustices.
- Pressure from leadership and peers.
- Emotional labor in conflicts and crises.

Stewards should:

- Work in teams, not alone.
- Rotate responsibilities.
- Have explicit terms (e.g., 1–2 years) with options to step back.
- Build cross-institutional support networks.

---

## 9. Growing the Steward Ecosystem

Long-term resilience requires **many** Stewards across:

- Sectors (health, education, finance, justice, media, etc.)
- Scales (org, city, region, network)
- Cultures and countries

Ways to grow:

- Training programs and bootcamps.
- Peer-learning networks.
- Shared handbooks, templates, and case studies.
- Recognition and career paths for Stewards.

---

## 10. A Draft Steward’s Oath

You may adapt this to your context and culture.

> I will use my access, insight, and influence  
> to protect the dignity, agency, and truth  
> of the people affected by the systems I help oversee.  
> I will not worship the machine, the market, or the state.  
> I will work with others, welcome scrutiny,  
> and accept that I will one day be replaced  
> by better stewards in a more just world.

---

This Handbook is **v2.0** — deliberately incomplete.

Its main purpose is to **start the practice**, not to finish it.
